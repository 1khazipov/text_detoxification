{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I'm using colab for testing my baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmMuBxerh47W"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1Xg01PfhVKX"
      },
      "outputs": [],
      "source": [
        "!pip install datasets==2.11\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pk5BXtKag3o0",
        "outputId": "b580b6d7-21ff-4700-fa0f-59235db5e59c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-02de5c1d21c8>:11: UserWarning: ignore\n",
            "  warnings.warn(\"ignore\")\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import spacy\n",
        "from datasets import load_dataset, load_metric, list_metrics\n",
        "import evaluate\n",
        "import warnings\n",
        "warnings.warn(\"ignore\")\n",
        "\n",
        "\n",
        "def create_dataframe(zip_file_path):\n",
        "    # check if zip file exists\n",
        "    if not os.path.exists(zip_file_path):\n",
        "        print(f\"zip file '{zip_file_path}' does not exist.\")\n",
        "        return None\n",
        "\n",
        "    # extract zip file\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        # Extract all files in the ZIP archive to a directory\n",
        "        extraction_path = \"./tmp_extraction\"\n",
        "        zip_ref.extractall(extraction_path)\n",
        "\n",
        "    # find .tsv file\n",
        "    tsv_file = None\n",
        "    for root, dirs, files in os.walk(extraction_path):\n",
        "        for file in files:\n",
        "            if file.endswith(\".tsv\"):\n",
        "                tsv_file = os.path.join(root, file)\n",
        "                break\n",
        "\n",
        "    if tsv_file is None:\n",
        "        print(\"No .tsv file found in the extracted ZIP archive.\")\n",
        "        return None\n",
        "\n",
        "    # create pandas DataFrame\n",
        "    try:\n",
        "        df = pd.read_csv(tsv_file, delimiter='\\t')\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error while creating DataFrame: {str(e)}\")\n",
        "        return None\n",
        "    finally:\n",
        "        # remove the temporary extraction directory\n",
        "        if os.path.exists(extraction_path):\n",
        "            for root, dirs, files in os.walk(extraction_path):\n",
        "                for file in files:\n",
        "                    file_path = os.path.join(root, file)\n",
        "                    os.remove(file_path)\n",
        "            os.rmdir(extraction_path)\n",
        "\n",
        "\n",
        "def create_new_columns(dataset):\n",
        "    # create new columns\n",
        "    # dataset['toxic'] = [''] * dataset.shape[0]\n",
        "    # dataset['nontoxic'] = [''] * dataset.shape[0]\n",
        "    # dataset['toxic_tox'] = [''] * dataset.shape[0]\n",
        "    # dataset['nontoxic_tox'] = [''] * dataset.shape[0]\n",
        "\n",
        "    # create the 'toxic' and 'nontoxic' columns\n",
        "    dataset['toxic'] = dataset.apply(lambda row: row['reference'] if row['ref_tox'] > row['trn_tox'] else row['translation'], axis=1)\n",
        "    dataset['nontoxic'] = dataset.apply(lambda row: row['translation'] if row['ref_tox'] > row['trn_tox'] else row['reference'], axis=1)\n",
        "\n",
        "    # create the 'toxic_tox' and 'nontoxic_tox' columns\n",
        "    dataset['toxic_tox'] = dataset.apply(lambda row: row['ref_tox'] if row['ref_tox'] > row['trn_tox'] else row['trn_tox'], axis=1)\n",
        "    dataset['nontoxic_tox'] = dataset.apply(lambda row: row['trn_tox'] if row['ref_tox'] > row['trn_tox'] else row['ref_tox'], axis=1)\n",
        "\n",
        "    # drop unuseful columns\n",
        "    dataset = dataset.drop(columns=['reference', 'translation', 'similarity', 'lenght_diff', 'ref_tox', 'trn_tox'])\n",
        "\n",
        "    return dataset\n",
        "    # return dataset['toxic'].tolist(), dataset['nontoxic'].tolist()\n",
        "\n",
        "\n",
        "def remove_unuseful_data(dataset):\n",
        "    # toxic sentences > 0.75 of toxic_tox: 0.9243254750535241\n",
        "    dataset = dataset[dataset['toxic_tox'] > 0.75]\n",
        "\n",
        "    # detoxed sentences < 0.25 of nontoxic_tox: 0.959344176040237\n",
        "    dataset = dataset[dataset['nontoxic_tox'] < 0.25]\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def get_sentences(dataset):\n",
        "    # toxic and detoxed sentences\n",
        "    return dataset['toxic'].tolist(), dataset['nontoxic'].tolist()\n",
        "\n",
        "\n",
        "def split_train_test(toxic, nontoxic, path):\n",
        "    toxic_train, toxic_test, nontoxic_train, nontoxic_test = train_test_split(\n",
        "        toxic,\n",
        "        nontoxic,\n",
        "        test_size=0.25,\n",
        "        random_state=42,\n",
        "    )\n",
        "\n",
        "    with open(os.path.join(path, 'toxic_train'), \"w\", encoding=\"UTF-8\") as file:\n",
        "        file.write(\"\\n\".join(toxic_train))\n",
        "    with open(os.path.join(path, 'toxic_test'), \"w\", encoding=\"UTF-8\") as file:\n",
        "        file.write(\"\\n\".join(toxic_test))\n",
        "    with open(os.path.join(path, 'nontoxic_train'), \"w\", encoding=\"UTF-8\") as file:\n",
        "        file.write(\"\\n\".join(nontoxic_train))\n",
        "    with open(os.path.join(path, 'nontoxic_test'), \"w\", encoding=\"UTF-8\") as file:\n",
        "        file.write(\"\\n\".join(nontoxic_test))\n",
        "\n",
        "def save_csv(dataset):\n",
        "    dataset.to_csv(\"converted.csv\")\n",
        "\n",
        "def get_dict():\n",
        "    return load_dataset(\"csv\", data_files=\"converted.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qnCT4LJ3hEW0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
        "\n",
        "class ToxicityClassifier:\n",
        "    def __init__(self, model_name='s-nlp/roberta_toxicity_classifier_v1'):\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.model = RobertaForSequenceClassification.from_pretrained(model_name).to(self.device)\n",
        "        self.tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    def text_toxicity(self, texts):\n",
        "        \"\"\"\n",
        "        baseline model\n",
        "        https://huggingface.co/s-nlp/roberta_toxicity_classifier_v1\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            input_ids = self.tokenizer(texts, return_tensors='pt', padding=True).to(self.device)\n",
        "            logits = self.model(**input_ids).logits\n",
        "            probabilities = torch.softmax(logits, -1)\n",
        "            toxicity_scores = probabilities[:, 1].cpu().numpy()\n",
        "        return toxicity_scores\n",
        "\n",
        "    def delete_toxic(self, toxic_sentences, threshold=0.5):\n",
        "        \"\"\"\n",
        "        remove toxic words from a list of sentences\n",
        "        \"\"\"\n",
        "        nontoxic_text = []\n",
        "        for toxic_sentence in toxic_sentences:\n",
        "            words = toxic_sentence.split()\n",
        "            toxic_scores = self.text_toxicity(words)\n",
        "            nontoxic_words = []\n",
        "            for word, score in zip(words, toxic_scores):\n",
        "                if score < threshold:\n",
        "                    nontoxic_words.append(word)\n",
        "            nontoxic_text.append(\" \".join(nontoxic_words))\n",
        "        return nontoxic_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lVLucggvh24L"
      },
      "outputs": [],
      "source": [
        "dataset = create_dataframe(\"drive/MyDrive/filtered_paranmt.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LeEG9V5Wh3IV"
      },
      "outputs": [],
      "source": [
        "dataset = create_new_columns(dataset)\n",
        "dataset = remove_unuseful_data(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ssSyw0NOiI1m"
      },
      "outputs": [],
      "source": [
        "toxic, nontoxic = get_sentences(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxZvcdCqiPz2",
        "outputId": "f381affe-285f-4520-d23f-ce1af3254bb7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at s-nlp/roberta_toxicity_classifier_v1 were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "clf = ToxicityClassifier()\n",
        "\n",
        "deleted_toxic = clf.delete_toxic(toxic[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RrQ36y7ifdg",
        "outputId": "eb091cb0-a885-4769-b61c-59af1de13c05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['if Alkar floods her with her mental waste, it would explain the high levels of neurotransmitter.',\n",
              " \"you're becoming\",\n",
              " 'well, we can spare your life.',\n",
              " 'you have to wake up.',\n",
              " 'I have orders to her.',\n",
              " \"I'm not gonna have a child... ...with the same genetic disorder as me who's gonna L...\",\n",
              " \"They're all laughing at us, so we'll kick your\",\n",
              " 'Maine was very short on people back then.',\n",
              " 'Briggs, what the hell is going on?',\n",
              " \"another simply didn't know what to do, so whenever he met my brother, he nearly beat the out of him.\"]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "deleted_toxic[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ugN4pufi4Ck",
        "outputId": "731081b0-84be-44d0-a25a-d17d02732036"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['if Alkar floods her with her mental waste, it would explain the high levels of neurotransmitter.',\n",
              " \"you're becoming disgusting.\",\n",
              " 'well, we can spare your life.',\n",
              " 'monkey, you have to wake up.',\n",
              " 'I have orders to kill her.',\n",
              " \"I'm not gonna have a child... ...with the same genetic disorder as me who's gonna die. L...\",\n",
              " \"They're all laughing at us, so we'll kick your ass.\",\n",
              " 'Maine was very short on black people back then.',\n",
              " 'Briggs, what the hell is going on?',\n",
              " \"another simply didn't know what to do, so whenever he met my brother, he nearly beat the shit out of him.\"]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "toxic[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "oMnl5TpKi7uL"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "def cleanup():\n",
        "    if torch.cuda.is_available():\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "cleanup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXYpaMGAjA8J"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
